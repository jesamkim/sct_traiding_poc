{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb017ab4-a16a-4c67-b875-a29eed6aa5bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OpenSearch를 통한 Simple RAG with LlamaIndex\n",
    ">이 노트북은,\n",
    "> - SageMaker Studio* **`Data Science 3.0`** kernel 및 ml.m5.large 인스턴스에서 테스트 되었습니다.\n",
    "> - SageMaker Notebook **`conda_python3`** 에서 테스트 되었습니다.\n",
    "\n",
    "\n",
    "여기서는 OpenSearch 가 설치된 것을 가정하고, 한글 형태소 분석기의 사용하는 법을 알려 드립니다.\n",
    "\n",
    "---\n",
    "\n",
    "### [중요]\n",
    "- 이 노트북은 Bedrock Titan Embedding Model 을 기본으로 사용합니다. \n",
    "- 오픈 서치 서비스가 액티브 된 상태를 가정 합니다.\n",
    "- 앞서 02_setup_openSearch_simple 노트북이 모두 완료가 되어 있어야 합니다.\n",
    "\n",
    "\n",
    "---\n",
    "## Ref: \n",
    "- [Amazon OpenSearch Service로 검색 구현하기](https://catalog.us-east-1.prod.workshops.aws/workshops/de4e38cb-a0d9-4ffe-a777-bf00d498fa49/ko-KR/indexing/blog-reindex)\n",
    "- [OpenSearch Python Client](https://opensearch.org/docs/1.3/clients/python-high-level/)\n",
    "- [OpenSearch Match, Multi-Match, and Match Phrase Queries](https://opster.com/guides/opensearch/opensearch-search-apis/opensearch-match-multi-match-and-match-phrase-queries/)\n",
    "- OpenSearch Query 에서 Filter, Must, Should, Not Mush 에 대한 설명 입니다.\n",
    "    - [OpenSearch Boolean Queries](https://opster.com/guides/opensearch/opensearch-search-apis/opensearch-boolean-queries/#:~:text=Boolean%20queries%20are%20used%20to,as%20terms%2C%20match%20and%20query_string.)\n",
    "- [OpenSearch Query Description (한글)](https://esbook.kimjmin.net/05-search)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f9c19-c43c-435c-944d-77984b54a6d8",
   "metadata": {},
   "source": [
    "## 1. 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb51172-fd95-479a-859a-90e373977c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opensearch_dsl==2.1.0 in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from opensearch_dsl==2.1.0) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from opensearch_dsl==2.1.0) (2.9.0)\n",
      "Requirement already satisfied: opensearch-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from opensearch_dsl==2.1.0) (2.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from opensearch-py>=2.2.0->opensearch_dsl==2.1.0) (2.32.3)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /opt/conda/lib/python3.10/site-packages (from opensearch-py>=2.2.0->opensearch_dsl==2.1.0) (2024.6.2)\n",
      "Requirement already satisfied: Events in /opt/conda/lib/python3.10/site-packages (from opensearch-py>=2.2.0->opensearch_dsl==2.1.0) (0.5)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.26.18 in /opt/conda/lib/python3.10/site-packages (from opensearch-py>=2.2.0->opensearch_dsl==2.1.0) (1.26.19)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py>=2.2.0->opensearch_dsl==2.1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py>=2.2.0->opensearch_dsl==2.1.0) (3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install opensearch_dsl==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787df0f0-7fd9-47ca-a0c3-91b3037d6a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef075cde-1ce7-4925-9b3d-db0cb18d5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from utils.ssm import parameter_store\n",
    "\n",
    "region=boto3.Session().region_name\n",
    "pm = parameter_store(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f13345-38a0-48cc-89a2-90ed2720722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = pm.get_params(\n",
    "    key=\"opensearch_domain_endpoint\",\n",
    "    enc=False\n",
    ")\n",
    "\n",
    "opensearch_user_id = pm.get_params(\n",
    "    key=\"opensearch_user_id\",\n",
    "    enc=False\n",
    ")\n",
    "\n",
    "opensearch_user_password = pm.get_params(\n",
    "    key=\"opensearch_user_password\",\n",
    "    enc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c66641-912e-4462-ba5f-27449aa0e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = opensearch_domain_endpoint\n",
    "opensearch_user_id = opensearch_user_id\n",
    "opensearch_user_password = opensearch_user_password\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cf3b9-26a3-4096-a6e4-4b9a39d2e82f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e9a4a1-ba92-422a-96b3-c52e0b826b47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Titan Text Large', 'amazon.titan-tg1-large'),\n",
      " ('Titan Image Generator G1', 'amazon.titan-image-generator-v1'),\n",
      " ('Titan Text G1 - Premier', 'amazon.titan-text-premier-v1:0'),\n",
      " ('Titan Text Embeddings v2', 'amazon.titan-embed-g1-text-02'),\n",
      " ('Titan Text G1 - Lite', 'amazon.titan-text-lite-v1'),\n",
      " ('Titan Text G1 - Express', 'amazon.titan-text-express-v1'),\n",
      " ('Titan Embeddings G1 - Text', 'amazon.titan-embed-text-v1'),\n",
      " ('Titan Text Embeddings V2', 'amazon.titan-embed-text-v2:0'),\n",
      " ('Titan Multimodal Embeddings G1', 'amazon.titan-embed-image-v1'),\n",
      " ('SDXL 1.0', 'stability.stable-diffusion-xl-v1'),\n",
      " ('J2 Grande Instruct', 'ai21.j2-grande-instruct'),\n",
      " ('J2 Jumbo Instruct', 'ai21.j2-jumbo-instruct'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid-v1'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra-v1'),\n",
      " ('Jamba-Instruct', 'ai21.jamba-instruct-v1:0'),\n",
      " ('Claude Instant', 'anthropic.claude-instant-v1'),\n",
      " ('Claude', 'anthropic.claude-v2:1'),\n",
      " ('Claude', 'anthropic.claude-v2'),\n",
      " ('Claude 3 Sonnet', 'anthropic.claude-3-sonnet-20240229-v1:0'),\n",
      " ('Claude 3 Haiku', 'anthropic.claude-3-haiku-20240307-v1:0'),\n",
      " ('Claude 3.5 Sonnet', 'anthropic.claude-3-5-sonnet-20240620-v1:0'),\n",
      " ('Command', 'cohere.command-text-v14'),\n",
      " ('Command R', 'cohere.command-r-v1:0'),\n",
      " ('Command R+', 'cohere.command-r-plus-v1:0'),\n",
      " ('Command Light', 'cohere.command-light-text-v14'),\n",
      " ('Embed English', 'cohere.embed-english-v3'),\n",
      " ('Embed Multilingual', 'cohere.embed-multilingual-v3'),\n",
      " ('Llama 2 Chat 13B', 'meta.llama2-13b-chat-v1'),\n",
      " ('Llama 2 Chat 70B', 'meta.llama2-70b-chat-v1'),\n",
      " ('Llama 3 8B Instruct', 'meta.llama3-8b-instruct-v1:0'),\n",
      " ('Llama 3 70B Instruct', 'meta.llama3-70b-instruct-v1:0'),\n",
      " ('Mistral 7B Instruct', 'mistral.mistral-7b-instruct-v0:2'),\n",
      " ('Mixtral 8x7B Instruct', 'mistral.mixtral-8x7b-instruct-v0:1'),\n",
      " ('Mistral Large', 'mistral.mistral-large-2402-v1:0'),\n",
      " ('Mistral Small', 'mistral.mistral-small-2402-v1:0')]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "from botocore.config import Config\n",
    "import botocore \n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "retry_config = Config(\n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    retries={\n",
    "        \"max_attempts\": 10,\n",
    "        \"mode\": \"standard\",\n",
    "    },\n",
    ")\n",
    "\n",
    "#modelId = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"  # Claude 3.5 Sonnet\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\" # Claude 3.0 Sonnet\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock')\n",
    "boto3_bedrock = boto3.client(service_name='bedrock-runtime',config=retry_config)\n",
    "\n",
    "model_list = bedrock.list_foundation_models()\n",
    "result = [(fm_list[\"modelName\"], fm_list[\"modelId\"]) for fm_list in model_list[\"modelSummaries\"] if fm_list['inferenceTypesSupported'] == ['ON_DEMAND']]\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7b1ce-4407-4164-b28e-84cfde5f32f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Titan Embedding 및 LLM 인 Claude-3 sonnet 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4292e3a-e33e-469d-b73d-3904919ab08b",
   "metadata": {},
   "source": [
    "### LLM 로딩 (Claude-v3 sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5d7ac7-f528-4ed3-a855-cdd519ddc17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b6ae65-4225-431f-a2c7-52fb22e814ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatBedrock(callbacks=[<langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x7f1cc0223a90>], client=<botocore.client.BedrockRuntime object at 0x7f1cc0269900>, region_name='us-east-1', model_id='anthropic.claude-3-sonnet-20240229-v1:0', model_kwargs={'anthropic_version': 'bedrock-2023-05-31', 'max_tokens': 4096, 'temperature': 0, 'top_k': 0, 'top_p': 0.0}, streaming=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_text = ChatBedrock(\n",
    "    model_id=modelId,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    model_kwargs={\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\" : 0,\n",
    "        \"top_k\": 0,\n",
    "        \"top_p\": 0.0\n",
    "    }\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0687e49d-2e95-4c17-acc8-b3d7949e0676",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생명보험과 손해보험은 보험의 주요 유형으로 다음과 같은 차이점이 있습니다.\n",
      "\n",
      "1. 보장 대상\n",
      "- 생명보험은 사람의 생명과 관련된 위험을 보장합니다. 예를 들어 사망, 상해, 질병 등을 대상으로 합니다.\n",
      "- 손해보험은 재산상의 손해나 배상책임을 보장합니다. 예를 들어 화재, 자동차사고, 배상책임 등을 대상으로 합니다.\n",
      "\n",
      "2. 보험금 지급 사유\n",
      "- 생명보험은 피보험자의 사망, 상해, 질병 등 인적 위험이 발생했을 때 보험금을 지급합니다.\n",
      "- 손해보험은 재물의 손해나 제3자에 대한 배상책임이 발생했을 때 실제 입은 손해를 보상합니다.\n",
      "\n",
      "3. 보험기간\n",
      "- 생명보험은 일반적으로 장기계약이며, 종신보험의 경우 피보험자 종신까지 보장됩니다.\n",
      "- 손해보험은 단기계약이 일반적이며, 1년 만기로 갱신하는 경우가 많습니다.\n",
      "\n",
      "4. 보험료 산정 기준\n",
      "- 생명보험료는 피보험자의 나이, 건강상태, 가입금액 등에 따라 결정됩니다.\n",
      "- 손해보험료는 보험목적물의 가액, 위험률, 보상한도 등에 따라 결정됩니다.\n",
      "\n",
      "요약하면 생명보험은 개인의 생명과 관련된 위험을 장기적으로 보장하고, 손해보험은 재산상 손해나 배상책임을 단기적으로 보상하는 것이 주요 차이점입니다."
     ]
    }
   ],
   "source": [
    "prompt1 = \"나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\"\n",
    "messages = [\n",
    "    HumanMessage(content=prompt1)\n",
    "]\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt1}]},\n",
    "# ]\n",
    "\n",
    "response1 = llm_text.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b9ad47-56b6-427d-84a6-4e792bf4f6f9",
   "metadata": {},
   "source": [
    "### Embedding 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65afde2a-097b-4a00-82e4-e7bab6e2a4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "llm_emb = BedrockEmbeddings(\n",
    "    client=boto3_bedrock,\n",
    "    # model_id=\"cohere.embed-multilingual-v3\"\n",
    "    model_id=\"amazon.titan-embed-g1-text-02\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f25b2-8b20-4b57-bc66-bf2b6004cc1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8090d-f864-4419-bf20-8135914c0876",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. OpenSearch 벡터 Index 생성\n",
    "### 선수 조건\n",
    "- 랭체인 오프서처 참고 자료\n",
    "    - [Langchain Opensearch](https://python.langchain.com/docs/integrations/vectorstores/opensearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c5796-a418-4505-ba28-0ca33c3fa9f8",
   "metadata": {},
   "source": [
    "### 오픈 서치 인덱스 유무에 따라 삭제\n",
    "오픈 서치에 해당 인덱스가 존재하면, 삭제 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b441a96e-6a2b-42d2-8b27-db78d5dd97d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "http_auth = (opensearch_user_id, opensearch_user_password)\n",
    "os_client = OpenSearch(\n",
    "            hosts=[\n",
    "                {'host': opensearch_domain_endpoint.replace(\"https://\", \"\"),\n",
    "                 'port': 443\n",
    "                }\n",
    "            ],\n",
    "            http_auth=http_auth, # Master username, Master password,\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            connection_class=RequestsHttpConnection\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac0292-f3fc-4ef7-a00d-becee90f0dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### index 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94fa9226-6be4-4d9d-b4d2-5bcab904a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 이름\n",
    "\n",
    "index_name = \"complex-doc-index-32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818bec59-9f17-4250-b133-a82767d79657",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index does not exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exists = os_client.indices.exists(index_name)\n",
    "\n",
    "if exists:\n",
    "    os_client.indices.delete(index=index_name)\n",
    "    print(\"Index is deleted\")\n",
    "else:\n",
    "    print(\"Index does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ad62cb-22ff-4031-b301-0baec1e5608d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"settings\": {\n",
      "    \"index.knn\": true,\n",
      "    \"index.knn.algo_param.ef_search\": 512\n",
      "  },\n",
      "  \"mappings\": {\n",
      "    \"properties\": {\n",
      "      \"metadata\": {\n",
      "        \"properties\": {\n",
      "          \"source\": {\n",
      "            \"type\": \"keyword\"\n",
      "          },\n",
      "          \"type\": {\n",
      "            \"type\": \"keyword\"\n",
      "          },\n",
      "          \"timestamp\": {\n",
      "            \"type\": \"date\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"vector_field\": {\n",
      "        \"type\": \"knn_vector\",\n",
      "        \"dimension\": 1536,\n",
      "        \"method\": {\n",
      "          \"engine\": \"faiss\",\n",
      "          \"name\": \"hnsw\",\n",
      "          \"parameters\": {\n",
      "            \"ef_construction\": 512,\n",
      "            \"m\": 16\n",
      "          },\n",
      "          \"space_type\": \"l2\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## metadata, text, vector_field 의 네이밍은 langchain에서 지정된 이름\n",
    "### model에 따라 dimension 사이즈 변경 필요 (Titan : 1536, Cohere : 1024)\n",
    "import json\n",
    "\n",
    "with open('index_body_simple.json', 'r') as f:\n",
    "    index_body = json.load(f)\n",
    "\n",
    "print(json.dumps(index_body, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66746526-4e79-4e41-a985-79697b5bb8ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True,\n",
       " 'shards_acknowledged': True,\n",
       " 'index': 'complex-doc-index-32'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_client.indices.create(index_name, body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb4971b6-777d-48a1-82dd-668a38e48587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 ms, sys: 673 μs, total: 2.77 ms\n",
      "Wall time: 2.42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "vector_db = OpenSearchVectorSearch(\n",
    "    index_name=index_name,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7070c1-8640-40cb-969d-1bc1a413d3f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. 데이터 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3942f101-dfb7-4f45-9ae6-1744d811ecbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /opt/conda/lib/python3.10/site-packages (0.10.53)\n",
      "Collecting llama-index-vector-stores-opensearch\n",
      "  Downloading llama_index_vector_stores_opensearch-0.1.12-py3-none-any.whl.metadata (729 bytes)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.2.8)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core==0.10.53.post1 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.10.53.post1)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.10)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.2.3)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.25)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.29)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.53.post1->llama-index) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (2023.6.0)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (0.27.0)\n",
      "Requirement already satisfied: llama-cloud<0.0.7,>=0.0.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (0.0.6)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.35.10)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (2.1.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (8.4.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core==0.10.53.post1->llama-index) (1.14.1)\n",
      "Requirement already satisfied: opensearch-py<3.0.0,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (2.6.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index) (0.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (2.9.0)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /opt/conda/lib/python3.10/site-packages (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (2024.6.2)\n",
      "Requirement already satisfied: Events in /opt/conda/lib/python3.10/site-packages (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (0.5)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.26.18 in /opt/conda/lib/python3.10/site-packages (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (1.26.19)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.53.post1->llama-index) (4.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /opt/conda/lib/python3.10/site-packages (from llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (2.7.3)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core==0.10.53.post1->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.53.post1->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.53.post1->llama-index) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core==0.10.53.post1->llama-index) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core==0.10.53.post1->llama-index) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.53.post1->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.53.post1->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core==0.10.53.post1->llama-index) (3.21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.53.post1->llama-index) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core==0.10.53.post1->llama-index) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core==0.10.53.post1->llama-index) (1.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.53.post1->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llama-cloud<0.0.7,>=0.0.6->llama-index-core==0.10.53.post1->llama-index) (2.18.4)\n",
      "Downloading llama_index_vector_stores_opensearch-0.1.12-py3-none-any.whl (6.7 kB)\n",
      "Installing collected packages: llama-index-vector-stores-opensearch\n",
      "Successfully installed llama-index-vector-stores-opensearch-0.1.12\n"
     ]
    }
   ],
   "source": [
    "# LLama Index 라이브러리 설치\n",
    "\n",
    "!pip install llama-index llama-index-vector-stores-opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aa129c7-64f1-4dac-a41a-47219bc619ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50966eee-578b-4211-8ca3-eb6bd3faae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일이 있는 디렉토리 경로 지정 (파일 명이 아닌 디렉토리로 지정)\n",
    "pdf_directory = \"./rag_data/\"\n",
    "\n",
    "# PDF 파일 로드\n",
    "documents = SimpleDirectoryReader(pdf_directory).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f95bb418-fd2e-4f16-b005-da04beaecf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processes: 7\n",
      "Indexing completed.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from langchain_core.documents import Document\n",
    "from datetime import datetime\n",
    "import os\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from multiprocessing import Manager\n",
    "\n",
    "def process_document(param):\n",
    "    vector_db, doc = param\n",
    "    source_name = os.path.basename(doc.metadata['file_name'])\n",
    "    type_name = source_name.split('_')[0]\n",
    "\n",
    "    pruned_text = doc.text.replace('\\n', ' ')\n",
    "\n",
    "    if len(pruned_text) >= 20:  # 임의로 20자 이상인 텍스트만 처리\n",
    "        chunk = Document(\n",
    "            page_content=pruned_text,\n",
    "            metadata={\n",
    "                \"source\": source_name,\n",
    "                \"type\": type_name,\n",
    "                \"timestamp\": datetime.now(),\n",
    "                \"page_label\": doc.metadata.get('page_label', '')\n",
    "            }\n",
    "        )\n",
    "        vector_db.add_documents([chunk])\n",
    "\n",
    "\n",
    "\n",
    "manager = Manager()\n",
    "result_dict = manager.dict()\n",
    "\n",
    "# documents 변수를 사용하여 파라미터 생성\n",
    "param = [(vector_db, doc) for doc in documents]\n",
    "\n",
    "num_processes = min(len(documents), os.cpu_count() - 1)\n",
    "if num_processes < 1:\n",
    "    num_processes = 1\n",
    "\n",
    "print(f\"Number of processes: {num_processes}\")\n",
    "\n",
    "with ThreadPool(processes=num_processes) as pool:\n",
    "    pool.map(process_document, param)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(\"Indexing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae62975-2e46-44e7-97e4-c14c2bfa632f",
   "metadata": {},
   "source": [
    "### OpenSearch에 생성된 인덱스의 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14827f89-c54b-440d-ab7f-5bb22eefc313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"complex-doc-index-32\": {\n",
      "    \"aliases\": {},\n",
      "    \"mappings\": {\n",
      "      \"properties\": {\n",
      "        \"metadata\": {\n",
      "          \"properties\": {\n",
      "            \"page_label\": {\n",
      "              \"type\": \"text\",\n",
      "              \"fields\": {\n",
      "                \"keyword\": {\n",
      "                  \"type\": \"keyword\",\n",
      "                  \"ignore_above\": 256\n",
      "                }\n",
      "              }\n",
      "            },\n",
      "            \"source\": {\n",
      "              \"type\": \"keyword\"\n",
      "            },\n",
      "            \"timestamp\": {\n",
      "              \"type\": \"date\"\n",
      "            },\n",
      "            \"type\": {\n",
      "              \"type\": \"keyword\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"text\": {\n",
      "          \"type\": \"text\",\n",
      "          \"fields\": {\n",
      "            \"keyword\": {\n",
      "              \"type\": \"keyword\",\n",
      "              \"ignore_above\": 256\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"vector_field\": {\n",
      "          \"type\": \"knn_vector\",\n",
      "          \"dimension\": 1536,\n",
      "          \"method\": {\n",
      "            \"engine\": \"faiss\",\n",
      "            \"space_type\": \"l2\",\n",
      "            \"name\": \"hnsw\",\n",
      "            \"parameters\": {\n",
      "              \"ef_construction\": 512,\n",
      "              \"m\": 16\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"settings\": {\n",
      "      \"index\": {\n",
      "        \"replication\": {\n",
      "          \"type\": \"DOCUMENT\"\n",
      "        },\n",
      "        \"number_of_shards\": \"5\",\n",
      "        \"knn.algo_param\": {\n",
      "          \"ef_search\": \"512\"\n",
      "        },\n",
      "        \"provided_name\": \"complex-doc-index-32\",\n",
      "        \"knn\": \"true\",\n",
      "        \"creation_date\": \"1720529568433\",\n",
      "        \"number_of_replicas\": \"1\",\n",
      "        \"uuid\": \"UTG_U8otSGGB4_Mr-l86DA\",\n",
      "        \"version\": {\n",
      "          \"created\": \"136327827\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index_info = os_client.indices.get(index=index_name)\n",
    "print(json.dumps(index_info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf67e77-15d5-4a8f-b0b5-a6d69baab68c",
   "metadata": {},
   "source": [
    "## 5. OpenSearch Hybrid 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa5119-13da-4e6a-a6f2-e6a1cba826ee",
   "metadata": {},
   "source": [
    "OpenSearch Hybrid 는 아래와 같은 방식으로 작동합니다.\n",
    "- (1) \"Vector 서치\" 하여 스코어를 얻은 후에 표준화를 하여 스코어를 구함. \n",
    "    - 전체 결과에서 가장 높은 스코어는 표준화 과정을 통하여 스코어가 1.0 이 됨.\n",
    "- (2) Keyword 서치도 동일하게 함.\n",
    "- (3) Reciprocal Rank Fusion (RRF) 기반 Re-rank\n",
    "    - Paper: https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf\n",
    "    - Desc: https://medium.com/@sowmiyajaganathan/hybrid-search-with-re-ranking-ff120c8a426d\n",
    "    - **RRF의 경우 score가 아닌 ranking 정보를 활용, 때문에 score normalization이 필요 없음**\n",
    "\n",
    "RRF는 langchain에서 \"Ensemble Retriever\" 이름으로 api를 제공합니다. \n",
    "- https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8f74d-ab29-4149-94e6-e85c6671a25e",
   "metadata": {},
   "source": [
    "### Ensemble retriever 정의\n",
    "- https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble\n",
    "- RRF 방식만 지원\n",
    "- Rank constant (param \"c\")\n",
    "    - This value determines how much influence documents in individual result sets per query have over the final ranked result set. A higher value indicates that lower ranked documents have more influence. This value must be greater than or equal to 1. Defaults to 60.\n",
    "    - 숫자 높을 수록 낮은 랭크의 문서가 더 중요시 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "792310d5-8117-49ea-a278-c3066052bee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearch_dsl import Search\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "# from utils.rag import run_RetrievalQA, show_context_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41e710fb-c2dd-4ae2-8f1c-984f01e37363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import BaseRetriever\n",
    "from typing import Any, Dict, List, Optional, List, Tuple\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "\n",
    "# lexical(keyword) search based (using Amazon OpenSearch)\n",
    "class OpenSearchLexicalSearchRetriever(BaseRetriever):\n",
    "    os_client: Any\n",
    "    index_name: str\n",
    "    k = 3\n",
    "    filter = []\n",
    "\n",
    "    def normalize_search_results(self, search_results):\n",
    "        hits = (search_results[\"hits\"][\"hits\"])\n",
    "        max_score = float(search_results[\"hits\"][\"max_score\"])\n",
    "        for hit in hits:\n",
    "            hit[\"_score\"] = float(hit[\"_score\"]) / max_score\n",
    "        search_results[\"hits\"][\"max_score\"] = hits[0][\"_score\"]\n",
    "        search_results[\"hits\"][\"hits\"] = hits\n",
    "        return search_results\n",
    "\n",
    "    def update_search_params(self, **kwargs):\n",
    "        self.k = kwargs.get(\"k\", 3)\n",
    "        self.filter = kwargs.get(\"filter\", [])\n",
    "        self.index_name = kwargs.get(\"index_name\", self.index_name)\n",
    "\n",
    "    def _reset_search_params(self, ):\n",
    "        self.k = 3\n",
    "        self.filter = []\n",
    "        \n",
    "    def query_lexical(self, query, filter=[], k=5):\n",
    "        QUERY_TEMPLATE = {\n",
    "            \"size\": k,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [\n",
    "                        {\n",
    "                            \"match\": {\n",
    "                                \"text\": {\n",
    "                                    \"query\": query,\n",
    "                                    \"operator\":  \"or\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"filter\": filter\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if len(filter) > 0:\n",
    "            QUERY_TEMPLATE[\"query\"][\"bool\"][\"filter\"].extend(filter)\n",
    "            \n",
    "        return QUERY_TEMPLATE\n",
    "    \n",
    "\n",
    "    def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun) -> List[Document]:\n",
    "        \n",
    "        query = self.query_lexical(\n",
    "            query=query,\n",
    "            filter=self.filter,\n",
    "            k=self.k\n",
    "        )\n",
    "\n",
    "        # print (\"lexical search query: \")\n",
    "        # print(query)\n",
    "        \n",
    "        search_results = self.os_client.search(\n",
    "            body=query,\n",
    "            index=self.index_name\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        if search_results[\"hits\"][\"hits\"]:\n",
    "            search_results = self.normalize_search_results(search_results)\n",
    "            for res in search_results[\"hits\"][\"hits\"]:\n",
    "\n",
    "                metadata = res[\"_source\"][\"metadata\"]\n",
    "                metadata[\"id\"] = res[\"_id\"]\n",
    "\n",
    "                doc = Document(\n",
    "                    page_content=res[\"_source\"][\"text\"],\n",
    "                    metadata=metadata\n",
    "                )\n",
    "                results.append((doc))\n",
    "\n",
    "        self._reset_search_params()\n",
    "\n",
    "        return results[:self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b944ed69-e539-4836-b4cf-87d2c8d16cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "\\n\\nHuman: 마지막에 질문 <question></question>에 대한 자세한 답변을 제공하기 위해 <context></context> 정보를 활용하세요.\n",
    "모르는 내용은 답변을 지어내려고 하지 말고 모른다고 말하세요.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>{question}</question>\n",
    "\n",
    "\\n\\nAssistant:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "766ae463-9a33-47d3-8e07-b1ffe9b5b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(\n",
    "    llm=llm_text,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=PROMPT,\n",
    "    verbose=False  # LLM 답변 과정을 출력하려면 True로 변경 합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d39a40d-71ec-4381-beea-cc6137ff7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 쿼리\n",
    "\n",
    "query = \"\"\"\n",
    "관세법상 환급 대상에는 어떤것들이 있고, 언제까지 어떻게 청구해야 되는지 알려줘.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafc584-c99d-4e3a-a372-a9dace882bb9",
   "metadata": {},
   "source": [
    "### Hybrid Search 방식으로 RAG 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67f1f241-5d70-40bd-90d7-2d0c6085b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_filter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee09fd1f-4e49-4819-bb39-c154e4388dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_semantic_retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"boolean_filter\": boolean_filter\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "321e0f38-ddcc-427f-8cff-957b19c523dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_lexical_retriever = OpenSearchLexicalSearchRetriever(\n",
    "    os_client=os_client,\n",
    "    index_name=index_name,\n",
    "    k=3,\n",
    "    filter=boolean_filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f691021b-9928-4554-b2cd-0d209d4adbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[opensearch_lexical_retriever, opensearch_semantic_retriever],\n",
    "    weights=[0.5, 0.5],\n",
    "    c=100,\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "631e6b7c-2047-4b46-9abb-9b5a33109967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "관세법상 환급 대상에는 다음과 같은 것들이 있습니다.\n",
      "\n",
      "1. 과오납금의 환급\n",
      "- 관세, 가산세, 강제징수비의 과오납금이 있는 경우 환급 대상이 됩니다.\n",
      "\n",
      "2. 계약내용과 상이한 물품에 대한 환급\n",
      "- 수입신고 물품이 계약내용과 상이하고 수입신고 당시 성질이나 형태가 변경되지 않은 경우, 수입신고수리일로부터 1년 이내에 보세구역에 반입하여 수출하거나 보세공장에 반입한 경우 환급 대상이 됩니다.\n",
      "\n",
      "3. 수입한 상태 그대로 수출되는 자가사용물품에 대한 관세환급\n",
      "- 개인의 자가사용물품을 수입한 상태 그대로 수출하는 경우로서 수입신고수리일부터 6개월 이내에 보세구역에 반입하여 수출하거나 세관장 확인 후 수출하는 경우 환급 대상이 됩니다.\n",
      "\n",
      "4. 지정보세구역 장치물품의 멸실, 손상으로 인한 관세환급\n",
      "- 수입신고 물품이 지정보세구역에 장치된 상태에서 재해로 멸실, 변질, 손상되어 가치가 감소한 경우 환급 대상이 됩니다.\n",
      "\n",
      "환급청구권은 권리를 행사할 수 있는 날부터 5년 이내에 관세청장이 지정한 세관에 환급신청을 해야 합니다. 구체적인 기산일은 사유별로 다릅니다.\n",
      "\n",
      "##############################\n",
      "query: \n",
      " \n",
      "관세법상 환급 대상에는 어떤것들이 있고, 언제까지 어떻게 청구해야 되는지 알려줘.\n",
      "\n",
      "\n",
      "answer: \n",
      " 관세법상 환급 대상에는 다음과 같은 것들이 있습니다.\n",
      "\n",
      "1. 과오납금의 환급\n",
      "- 관세, 가산세, 강제징수비의 과오납금이 있는 경우 환급 대상이 됩니다.\n",
      "\n",
      "2. 계약내용과 상이한 물품에 대한 환급\n",
      "- 수입신고 물품이 계약내용과 상이하고 수입신고 당시 성질이나 형태가 변경되지 않은 경우, 수입신고수리일로부터 1년 이내에 보세구역에 반입하여 수출하거나 보세공장에 반입한 경우 환급 대상이 됩니다.\n",
      "\n",
      "3. 수입한 상태 그대로 수출되는 자가사용물품에 대한 관세환급\n",
      "- 개인의 자가사용물품을 수입한 상태 그대로 수출하는 경우로서 수입신고수리일부터 6개월 이내에 보세구역에 반입하여 수출하거나 세관장 확인 후 수출하는 경우 환급 대상이 됩니다.\n",
      "\n",
      "4. 지정보세구역 장치물품의 멸실, 손상으로 인한 관세환급\n",
      "- 수입신고 물품이 지정보세구역에 장치된 상태에서 재해로 멸실, 변질, 손상되어 가치가 감소한 경우 환급 대상이 됩니다.\n",
      "\n",
      "환급청구권은 권리를 행사할 수 있는 날부터 5년 이내에 관세청장이 지정한 세관에 환급신청을 해야 합니다. 구체적인 기산일은 사유별로 다릅니다.\n"
     ]
    }
   ],
   "source": [
    "answer = chain.invoke(\n",
    "    {\n",
    "        \"input_documents\": ensemble_retriever.get_relevant_documents(query), \n",
    "        \"question\": query\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n\\n##############################\")\n",
    "print(\"query: \\n\", query)\n",
    "print(\"answer: \\n\", answer['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e505db-ebe6-40a4-9c8e-18520cf71171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8e647a79df62bf31906a725b05de775d285962ac600487339d38c51a5c07b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
